{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from faker import Faker\n",
    "\n",
    "# custom\n",
    "import utils\n",
    "\n",
    "# imports re for text cleaning\n",
    "import re\n",
    "from datetime import datetime, timedelta, date\n",
    "\n",
    "# we will ignore pandas warning\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all lightfm imports \n",
    "from lightfm.data import Dataset\n",
    "from lightfm import LightFM\n",
    "from lightfm import cross_validation\n",
    "from lightfm.evaluation import precision_at_k\n",
    "from lightfm.evaluation import auc_score\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_trans</th>\n",
       "      <th>inn_kt</th>\n",
       "      <th>inn_dt</th>\n",
       "      <th>c_sum</th>\n",
       "      <th>date</th>\n",
       "      <th>nazn</th>\n",
       "      <th>kt_group_num</th>\n",
       "      <th>dt_group_num</th>\n",
       "      <th>kt_group_name</th>\n",
       "      <th>dt_group_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>4153186486</td>\n",
       "      <td>8766161799</td>\n",
       "      <td>179954.68</td>\n",
       "      <td>2021-09-25</td>\n",
       "      <td>овощи</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>analysis</td>\n",
       "      <td>analysis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>7807062498</td>\n",
       "      <td>4826977470</td>\n",
       "      <td>56154.63</td>\n",
       "      <td>2021-11-02</td>\n",
       "      <td>фрукты</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>yet</td>\n",
       "      <td>yet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2489620450</td>\n",
       "      <td>9411708365</td>\n",
       "      <td>38962.65</td>\n",
       "      <td>2022-04-12</td>\n",
       "      <td>серсо</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>half</td>\n",
       "      <td>resource</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>7387179590</td>\n",
       "      <td>3301277896</td>\n",
       "      <td>248720.61</td>\n",
       "      <td>2023-09-26</td>\n",
       "      <td>серсо</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>couple</td>\n",
       "      <td>couple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>3745811688</td>\n",
       "      <td>3567683946</td>\n",
       "      <td>51635.07</td>\n",
       "      <td>2021-08-12</td>\n",
       "      <td>колесо</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>school</td>\n",
       "      <td>fall</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id_trans      inn_kt      inn_dt      c_sum        date    nazn  \\\n",
       "0         1  4153186486  8766161799  179954.68  2021-09-25   овощи   \n",
       "1         2  7807062498  4826977470   56154.63  2021-11-02  фрукты   \n",
       "2         3  2489620450  9411708365   38962.65  2022-04-12   серсо   \n",
       "3         4  7387179590  3301277896  248720.61  2023-09-26   серсо   \n",
       "4         5  3745811688  3567683946   51635.07  2021-08-12  колесо   \n",
       "\n",
       "   kt_group_num  dt_group_num kt_group_name dt_group_name  \n",
       "0            10            10      analysis      analysis  \n",
       "1             1             1           yet           yet  \n",
       "2             8             7          half      resource  \n",
       "3             4             4        couple        couple  \n",
       "4             3             9        school          fall  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df, inns, inn2group, group2name = utils.make_interactions_dataset(\n",
    "    num_transactions=5000,\n",
    "    num_inns=80,\n",
    "    num_groups=10\n",
    ")\n",
    "\n",
    "df_train, df_test = train_test_split(df, test_size=0.2)\n",
    "\n",
    "# dropping duplicate interactions from test which are present in train\n",
    "train_kt_dt_set = set(zip(df_train['inn_kt'], df_train['inn_dt']))\n",
    "df_test = df_test[~df_test[['inn_kt', 'inn_dt']].apply(tuple, axis=1).isin(train_kt_dt_set)]\n",
    "df_test = df_test.reset_index(drop=True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "kt_feature_list = utils.generate_feature_list(df_train, [\"kt_group_num\", \"kt_group_name\"])\n",
    "dt_feature_list = utils.generate_feature_list(df_test, [\"dt_group_num\", \"dt_group_name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating dataset\n",
    "dataset = Dataset()\n",
    "dataset.fit(\n",
    "    users=set(inns),\n",
    "    items=set(inns),\n",
    "    user_features=kt_feature_list,\n",
    "    item_features=dt_feature_list\n",
    ")\n",
    "\n",
    "interactions, weights = dataset.build_interactions(\n",
    "    data=list(zip(df_train[\"inn_kt\"], df_train[\"inn_dt\"]))\n",
    ")\n",
    "\n",
    "test_interactions, test_weights = dataset.build_interactions(\n",
    "    data=list(zip(df_test[\"inn_kt\"], df_test[\"inn_dt\"]))\n",
    ")\n",
    "\n",
    "# now we are building our questions and professionals features\n",
    "# in a way that lightfm understand.\n",
    "# we are using lightfm build in method for building\n",
    "# questions and professionals features \n",
    "kt_features = dataset.build_user_features(\n",
    "    utils.create_features(df_train, [\"kt_group_num\", \"kt_group_name\"], \"inn_kt\"),\n",
    "    normalize=True\n",
    ")\n",
    "\n",
    "dt_features = dataset.build_item_features(\n",
    "    utils.create_features(df_train, [\"dt_group_num\", \"dt_group_name\"], \"inn_dt\"),\n",
    "    normalize=True\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Columns in `dt_features` correspond to `dataset.mapping()` tuple of dictionaries for item features.\n",
    "\n",
    "**NOTE**: `dataset.mapping()` returns a tuple of 4 dictionaries:\n",
    "\n",
    "`_user_id_mapping`,\n",
    "\n",
    "`_user_feature_mapping`,\n",
    "\n",
    "`_item_id_mapping`,\n",
    "\n",
    "`_item_feature_mapping`\n",
    "\n",
    "**For example**, `_item_feature_mapping[\"Pharmacologist\"]` returns an index of `\"Pharmacologist\"` feature in `dt_features` matrix, so `dt_features[:, index]` shows the \"Pharmacologist\" feature value for all items."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "Epoch 1\n",
      "Epoch 2\n",
      "Epoch 3\n",
      "Epoch 4\n",
      "0.46253723\n",
      "0.021428572\n"
     ]
    }
   ],
   "source": [
    "model = LightFM(\n",
    "    no_components=150,\n",
    "    learning_rate=0.05,\n",
    "    loss='warp',\n",
    "    random_state=2024)\n",
    "\n",
    "model.fit(\n",
    "    interactions,\n",
    "    item_features=dt_features,\n",
    "    user_features=kt_features, sample_weight=weights,\n",
    "    epochs=5, num_threads=1, verbose=True)\n",
    "\n",
    "print(utils.calculate_auc_score(model, test_interactions, kt_features, dt_features))\n",
    "print(utils.calculate_precision_at_k(model, test_interactions, kt_features, dt_features))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making embedding mappings for dt and kt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "kt_biases, kt_embeds = model.get_user_representations(kt_features)\n",
    "dt_biases, dt_embeds = model.get_item_representations(dt_features)\n",
    "user_id_mapping, user_feature_mapping, item_id_mapping, item_feature_mapping = dataset.mapping()\n",
    "\n",
    "embeddings = {}\n",
    "for inn in inns:\n",
    "    # e.g.\n",
    "    # user_id_mapping[inn] - index of user in kt_embeds\n",
    "    embeddings[inn] = {\n",
    "        \"kt_embed\": kt_embeds[user_id_mapping[inn]],\n",
    "        \"dt_embed\": dt_embeds[item_id_mapping[inn]],\n",
    "        \"kt_bias\": kt_biases[user_id_mapping[inn]],\n",
    "        \"dt_bias\": dt_biases[item_id_mapping[inn]]\n",
    "    }"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obtaining predictions manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "# раз ВСЕХ, то и себя тоже что ли?\n",
    "kt_scores: Dict[int, Dict[int, float]] = {}\n",
    "for inn_kt in df_test[\"inn_kt\"]:\n",
    "    inn_idx = user_id_mapping[inn_kt]\n",
    "    kt_embed = embeddings[inn_kt][\"kt_embed\"]\n",
    "    kt_bias = embeddings[inn_kt][\"kt_bias\"]\n",
    "    scores = {}\n",
    "    for inn_dt in inns:\n",
    "        dt_idx = item_id_mapping[inn_dt]\n",
    "        dt_embed = embeddings[inn_dt][\"dt_embed\"]\n",
    "        dt_bias = embeddings[inn_dt][\"dt_bias\"]\n",
    "\n",
    "        score = (dt_embed @ kt_embed) + kt_bias + dt_bias\n",
    "        scores[inn_dt] = score\n",
    "\n",
    "    kt_scores[inn_kt] = scores"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Полуаем все взаимодействия (и на трейне и на тесте (?))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_kt_dt_set = set(zip(df_test['inn_kt'], df_test['inn_dt']))\n",
    "train_kt_dt_set = set(zip(df_train['inn_kt'], df_train['inn_dt']))\n",
    "all_set = train_kt_dt_set | test_kt_dt_set"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Считаем map"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем рекомендовать строго тех с кем ещё не взаимодействовали, поскольку их заведемо не будет в тестовом наборе"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1416732881657141\n"
     ]
    }
   ],
   "source": [
    "# kt датафрейм с предиктами\n",
    "kt_preds = pd.DataFrame(kt_scores)\n",
    "\n",
    "# считаем мапы\n",
    "average_precisions = {}\n",
    "average_precisions_no_index = []\n",
    "top_k = 20\n",
    "for inn_kt in kt_scores:\n",
    "    # составляем тех с кем ещё не взаимодействовали в трейне\n",
    "    data = kt_preds[inn_kt].sort_values(ascending=False)\n",
    "    data = data[[(inn_kt, inn_dt) not in train_kt_dt_set for inn_dt in data.index]][:top_k]\n",
    "    top_k_dt = data.index\n",
    "    top_k_scores = data.values\n",
    "\n",
    "    targets = np.array([(inn_kt, inn_dt) in test_kt_dt_set for inn_dt in top_k_dt])\n",
    "    total_ones = sum(targets)\n",
    "    \n",
    "    precisions = (targets.cumsum() / np.arange(1, top_k + 1)) * targets\n",
    "    if total_ones == 0:\n",
    "        average_precision = 0\n",
    "    else:\n",
    "        average_precision = precisions.sum() / total_ones\n",
    "    \n",
    "    average_precisions[inn_kt] = average_precision\n",
    "    average_precisions_no_index.append(average_precision)\n",
    "\n",
    "average_precisions_no_index = np.array(average_precisions_no_index)\n",
    "\n",
    "\n",
    "print(average_precisions_no_index.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модель обучена"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
